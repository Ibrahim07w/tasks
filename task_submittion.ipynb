{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tarfile\n",
    "import os\n",
    "import shutil\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ibrah\\AppData\\Local\\Temp\\ipykernel_22804\\3671447143.py:3: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall(path='C:/Users/ibrah/Downloads/audio_dataset')\n"
     ]
    }
   ],
   "source": [
    "tar_file_path = 'C:/Users/ibrah/Downloads/audio_dataset/flac_D_aa.tar'\n",
    "with tarfile.open(tar_file_path, 'r') as tar:\n",
    "    tar.extractall(path='C:/Users/ibrah/Downloads/audio_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "def time_stretch(audio, rate=1.2):\n",
    "    audio_np = audio.numpy()\n",
    "    stretched = librosa.effects.time_stretch(audio_np, rate)\n",
    "    return tf.convert_to_tensor(stretched, dtype=tf.float32)\n",
    "\n",
    "def pitch_shift(audio, sample_rate=16000, n_steps=2):\n",
    "    audio_np = audio.numpy()\n",
    "    shifted = librosa.effects.pitch_shift(audio_np, sample_rate, n_steps=n_steps)\n",
    "    return tf.convert_to_tensor(shifted, dtype=tf.float32)\n",
    "\n",
    "def add_noise(audio, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(audio)) * noise_factor\n",
    "    audio_with_noise = audio + noise\n",
    "    return tf.convert_to_tensor(audio_with_noise, dtype=tf.float32)\n",
    "\n",
    "def shift_audio(audio, max_shift=0.5, sample_rate=16000):\n",
    "    shift = np.random.randint(-int(max_shift * sample_rate), int(max_shift * sample_rate))\n",
    "    audio_shifted = tf.roll(audio, shift, axis=0)\n",
    "    return audio_shifted\n",
    "\n",
    "def change_volume(audio, gain_db_range=(-6, 6)):\n",
    "    gain_db = np.random.uniform(*gain_db_range)\n",
    "    audio = audio * (10**(gain_db / 20))\n",
    "    return tf.clip_by_value(audio, -1.0, 1.0)\n",
    "\n",
    "def augment_audio(audio):\n",
    "    augmentations = [time_stretch, pitch_shift, add_noise, shift_audio, change_volume]\n",
    "    augmentation = np.random.choice(augmentations)\n",
    "    if augmentation == time_stretch:\n",
    "        aug_audio = time_stretch(audio, rate=np.random.uniform(0.8, 1.2))\n",
    "    elif augmentation == pitch_shift:\n",
    "        aug_audio = pitch_shift(audio, n_steps=np.random.randint(-2, 3))\n",
    "    elif augmentation == add_noise:\n",
    "        aug_audio = add_noise(audio)\n",
    "    elif augmentation == shift_audio:\n",
    "        aug_audio = shift_audio(audio)\n",
    "    elif augmentation == change_volume:\n",
    "        aug_audio = change_volume(audio)\n",
    "    return audio, aug_audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mel_spectrogram(audio, sample_rate=44100, n_mels=128, fmax=1000):\n",
    "    y, sr = librosa.load(audio, sr=sample_rate)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, fmax=fmax)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    mel_spectrogram = np.expand_dims(mel_spectrogram, axis=-1)\n",
    "    return mel_spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, sample_rate=16000):\n",
    "    audio = tf.io.read_file(filename)\n",
    "    audio, _ = tf.audio.decode_wav(audio, desired_channels=1)\n",
    "    audio = tf.squeeze(audio, axis=-1)  # Remove the last dimension\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    audio = tfio.audio.resample(audio, rate_in=44100, rate_out=sample_rate)  # Resample audio\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset = 'C:/Users/ibrah/Downloads/audio_dataset/flac_D'\n",
    "audio_files = [f for f in os.listdir(audio_dataset) if f.endswith('.flac')]\n",
    "aug_dataset = []\n",
    "for file in audio_files:\n",
    "    audio_path = os.path.join(audio_dataset, file)\n",
    "    audio = load_audio(audio_path)\n",
    "    aug_audio = augment_audio(audio)\n",
    "    mel_spec = to_mel_spectrogram(aug_audio)\n",
    "    aug_dataset.append(mel_spec)\n",
    "spectrograms = np.array(aug_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_0062 D_0000000001 F - - - AC1 A11 spoof -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D_0755 D_0000000022 F - - - AC3 A16 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D_0106 D_0000000043 M - - - AC2 A15 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D_5368 D_0000000064 M - - - AC2 A12 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D_3166 D_0000000085 M - - - AC2 A15 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D_4932 D_0000000106 M - - - AC2 A16 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47395</th>\n",
       "      <td>D_0375 D_0000995317 M - - - - bonafide bonafide -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47396</th>\n",
       "      <td>D_1956 D_0000995338 F - - - - bonafide bonafide -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47397</th>\n",
       "      <td>D_5214 D_0000995359 M - - - AC1 A13 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47398</th>\n",
       "      <td>D_2809 D_0000995380 M - - - AC1 A11 spoof -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47399</th>\n",
       "      <td>D_0637 D_0000995401 F - - - - bonafide bonafide -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47400 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             D_0062 D_0000000001 F - - - AC1 A11 spoof -\n",
       "0            D_0755 D_0000000022 F - - - AC3 A16 spoof -\n",
       "1            D_0106 D_0000000043 M - - - AC2 A15 spoof -\n",
       "2            D_5368 D_0000000064 M - - - AC2 A12 spoof -\n",
       "3            D_3166 D_0000000085 M - - - AC2 A15 spoof -\n",
       "4            D_4932 D_0000000106 M - - - AC2 A16 spoof -\n",
       "...                                                  ...\n",
       "47395  D_0375 D_0000995317 M - - - - bonafide bonafide -\n",
       "47396  D_1956 D_0000995338 F - - - - bonafide bonafide -\n",
       "47397        D_5214 D_0000995359 M - - - AC1 A13 spoof -\n",
       "47398        D_2809 D_0000995380 M - - - AC1 A11 spoof -\n",
       "47399  D_0637 D_0000995401 F - - - - bonafide bonafide -\n",
       "\n",
       "[47400 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('C:/Users/ibrah/Downloads/audio_dataset/protocols/ASVspoof5.dev.track_1.tsv', sep='\\t')\n",
    "labels = labels.head(47400)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.columns=['labels']\n",
    "labels['labels'] = labels['labels'].apply(lambda x: 1 if 'spoof' in x.lower() else (0 if 'bonafide' in x.lower() else x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "\n",
    "for index, row in labels.iterrows():\n",
    "    new_rows.append(row)  \n",
    "    new_rows.append(row)  \n",
    "\n",
    "new_labels = pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spectrograms\n",
    "y = np.array(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_normalized = scaler.fit_transform(x.reshape(-1, x.shape[-1])).reshape(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x_train_full, x_val, y_train_full, y_val = train_test_split(x_normalized, y, test_size=0.1, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=2)  \n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specrnet = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (3,3), initializer='lecun', activation='selu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.MaxPooling((2,2)),\n",
    "    keras.layers.Conv2D(64, (3,3), initializer='lecun', activation='selu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.MaxPooling((2,2)),\n",
    "    keras.layers.Conv2D(128, (3,3), initializer='lecun', activation='selu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.MaxPooling((2,2)),\n",
    "    keras.layers.Conv2D(256, (3,3), initializer='lecun', activation='selu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.MaxPooling((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='selu', initializer='lecun'),\n",
    "    keras.layers.Dropout(0.45),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "specrnet.compile(optimizer='nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "specrnet.summary()\n",
    "history = specrnet.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "val_loss, val_acc = specrnet.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
